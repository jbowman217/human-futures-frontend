# ğŸ§  Train It Right

## ğŸ’­ Prethinking Ideas
- What happens if an AI is trained on only half the picture?
- Who or what gets left out of data â€” and why?
- When have you been misjudged because of a label?

## â“ Prethinking Questions
- What does it mean to â€œtrainâ€ a model?
- What makes data â€œrepresentativeâ€ or â€œbiasedâ€?
- Can fairness be programmed?

---

## ğŸ¤– Task 1: Meet the Model

Use Machine Learning for Kids (ML4K) to build a basic classifier.

- Option 1: Titanic Survivors (binary classification, pre-loaded dataset)
- Option 2: Make Me Happy (user-generated compliments vs. insults)

> ğŸ¯ Train the model and explore the decision tree. What features influence predictions?

---

## ğŸ§ª Task 2: Audit the Data

Critique your dataset.

- What kinds of examples are missing?
- What hidden assumptions are baked into the labels?
- What happens when you test edge cases?

> ğŸ¯ Make a plan to rebalance or improve your data

---

## ğŸ§  Task 3: Refine and Test

Retrain your model with your revised dataset.

- Run it against real-world or invented scenarios
- Compare performance: What got better? What stayed wrong?
- Reflect on fairness, accuracy, and unintended consequences

> ğŸ¯ Bonus: Share your results in a â€œBias Bustersâ€ presentation or chart

---

## ğŸ’¬ Reflection

- What does it mean to train something ethically?
- Can AI ever truly be fair â€” or just less unfair?
- What do your modelâ€™s errors say about your assumptions?

---

## ğŸ¨ Remix

- Invent a machine learning project that centers *underrepresented voices*
- Turn your bias discovery into a comic, infographic, or short video
- Build a campaign: â€œTrain the AI Right â€” Here's Howâ€
