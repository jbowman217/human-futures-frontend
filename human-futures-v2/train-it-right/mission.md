# 🧠 Train It Right

## 💭 Prethinking Ideas
- What happens if an AI is trained on only half the picture?
- Who or what gets left out of data — and why?
- When have you been misjudged because of a label?

## ❓ Prethinking Questions
- What does it mean to “train” a model?
- What makes data “representative” or “biased”?
- Can fairness be programmed?

---

## 🤖 Task 1: Meet the Model

Use Machine Learning for Kids (ML4K) to build a basic classifier.

- Option 1: Titanic Survivors (binary classification, pre-loaded dataset)
- Option 2: Make Me Happy (user-generated compliments vs. insults)

> 🎯 Train the model and explore the decision tree. What features influence predictions?

---

## 🧪 Task 2: Audit the Data

Critique your dataset.

- What kinds of examples are missing?
- What hidden assumptions are baked into the labels?
- What happens when you test edge cases?

> 🎯 Make a plan to rebalance or improve your data

---

## 🧠 Task 3: Refine and Test

Retrain your model with your revised dataset.

- Run it against real-world or invented scenarios
- Compare performance: What got better? What stayed wrong?
- Reflect on fairness, accuracy, and unintended consequences

> 🎯 Bonus: Share your results in a “Bias Busters” presentation or chart

---

## 💬 Reflection

- What does it mean to train something ethically?
- Can AI ever truly be fair — or just less unfair?
- What do your model’s errors say about your assumptions?

---

## 🎨 Remix

- Invent a machine learning project that centers *underrepresented voices*
- Turn your bias discovery into a comic, infographic, or short video
- Build a campaign: “Train the AI Right — Here's How”
