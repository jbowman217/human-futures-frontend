# 🎯 Mission: Who’s the Algorithm Really Guessing?

## 💭 Prethinking Ideas
- What’s something you've been wrongly labeled as? By who?
- How do systems group or sort people? Are those groupings fair?

## ❓ Prethinking Questions
- Can AI make better decisions than people?
- What makes a classification accurate or biased?
- How do decision trees work in tech... and in society?

---

## 🔧 Task 1: Sort It Out

You're the human algorithm. You’ve been given a messy dataset of [sports, artists, languages, or foods].

Your job: Sort them into categories — any way you want. But be ready to explain your logic.  
- What criteria did you use?
- What got left out?
- Would everyone agree with your groupings?

> 🛠️ Materials: Sticky notes or a sorting app like Lucidchart

---

## 🧠 Task 2: Build a Classifier

Now you're building a **decision tree** to simulate an AI classifier.

Your job:
- Pick a category (e.g., artists, instruments, countries, sneakers, political quotes)
- Build a yes/no tree that classifies at least 8 examples
- Test it with a partner

> 🧠 Use tools like: [Coggle.it, Google Drawings, or paper branches]

---

## 🤖 Task 3: Simulate the Algorithm

Run a **Guessing Game** powered by your tree.

- One student secretly picks an item
- Another student (acting as the AI) asks only yes/no questions from your tree to guess it
- Switch roles and refine your tree for better accuracy

---

## 💬 Reflection

- What patterns or flaws did your decision tree reveal?
- Were there moments where human reasoning outperformed your AI structure?
- How does this exercise relate to the way social media, policing, or job filters classify people?
- What happens when the training data leaves someone out?

---

## 🎨 Remix

- Redesign your classifier for justice: How would you rework the logic to be more fair, inclusive, or community-centered?
- Build a tree for activism: How would you classify protest strategies, or climate actions, or media messages?
- Create a “Bias Detector” tree — where each leaf tells you the kind of bias a system might be making.

---
