## ðŸŒ± Reflection Prompts

1. Whatâ€™s one time your robot made the wrong decision â€” and why?
2. How do sensors and logic shape what a robot *sees* and does?
3. When should a robot defer to a human?
4. What values are encoded into your robotâ€™s rules?
5. Could your robot make decisions that cause harm â€” even if unintentional?
